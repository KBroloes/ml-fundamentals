{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Balancing\n",
    "\n",
    "**Author: [Kevin Brol√∏s](https://abzu.ai/team)**\n",
    "\n",
    "This notebook will go through balancing datasets.\n",
    "It's mostly used for classification, though there are also methods for regression, but they are a bit more advanced and out of scope for this course.\n",
    "\n",
    "Usually, you consider balancing for classification with respect to the output variable. There are definitely balancing issues to consider for your input features as well (as hinted at during analysis and preparation, you want your data columns to be representative of the true distribution, whatever it may be), but we are going to only look at how to prepare your dataset to avoid skewing learning towards a single class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling methods\n",
    "\n",
    "It is most commonly fixed when splitting and sampling your data prior to training. There are a few commonly used methods for this. There are also some advanced methods like SMOTE, which we will not go into here, but is an excellent follow-up topic once you've understood these.\n",
    "\n",
    "## What is sampling?\n",
    "\n",
    "Sampling refers to the process of picking the individual samples (data points) from your data set. It comes from statistical terms of sampling a distribution. You can do so randomly, with or without replacement, entirely, or using some more clever approaches as we will describe.\n",
    "\n",
    "The result will be that the new sampled set will have a different representation and you want that to be as fair as possible for modelling.\n",
    "\n",
    "Consider a binary classification dataset (a dataset with two output classes).\n",
    "\n",
    "Let's call this: \n",
    "### Case 1\n",
    "If one of the classes make up 25% of the dataset and the other class 75% of the dataset, we would consider it unbalanced. It could be represented like this:\n",
    "**\\[25, 75\\]**. \n",
    "\n",
    "In this case, class 1 would be the minority class and class 2 the majority class.\n",
    "\n",
    "You can also have something like:\n",
    "### Case 2\n",
    "You can also have three classes, with the distribution, for example: \n",
    "\n",
    "**\\[15, 35, 50\\]**, \n",
    "\n",
    "which has two minority classes and one majority.\n",
    "\n",
    "And of course many more.\n",
    "\n",
    "Both of these cases would skew the learning towards the majority class, as that class has more points that influence the model than the remaining cases. In short, the model learns more about that class than the rest.\n",
    "\n",
    "An unbalanced problem also means that just always guessing the majority class would give a 75% and 50% success rate on the model, respectively for the two cases.\n",
    "\n",
    "## Oversampling\n",
    "\n",
    "Oversampling is the process of sampling the minority class **more** times, with replacement, to get it up to the same level as the majority class. So if we take case 1: \\[25, 75\\]\n",
    "\n",
    "You would sample class 2 entirely - so 75 samples. You would then either:\n",
    "* Sample class 1 entirely - 3 times - to get to 75 (you can calculate this ratio for automation)\n",
    "* Sample class 1 75 times with replacement to get up to the same representation\n",
    "\n",
    "In both cases, you now end up with a 150 samples instead of the original 100, as the minority class has duplicated samples to ensure the model learns evenly from both. Which one of these you prefer to use could be decided from some consideration of the sparsity of the data, and whether you trust you'll get a good distribution out of sampling it versus repeating it.\n",
    "Sampling is generally preferred as you don't make decisions on ordering of data - however there are cases where you can decide to repeat instead.\n",
    "\n",
    "## Undersampling\n",
    "\n",
    "Undersampling is the process of sampling the majority class **fewer** times, without replacement, to get it down to the same level as the minority class. So if we take case 1: \\[25, 75\\]\n",
    "\n",
    "You would sample class 1 entirely - so 25 samples. You would then take 25 random samples among the original 75 of class 2.\n",
    "\n",
    "The downside to this is you end up not using all of your data. You end up with 50 samples rather than the original 100, and you have to trust that your sampling is representative - which becomes less and less likely the fewer data points you use. If you have thousands or millions of well-distributed points, this can be a fine strategy. If you have 100 as in this case, oversampling would usually be preferred.\n",
    "\n",
    "## Mixed Sampling\n",
    "\n",
    "Mixed sampling is a combination of both of the two procedures. You can either take case 1, and sample both to the halfway point, or, as is more customary, you can define the midpoint among multiple classes as in case 2, and sample the minority up and the majority down.\n",
    "\n",
    "So taking case 2: \\[15, 35, 50\\]\n",
    "\n",
    "Mixed sampling would mean sampling the entirety of class 2, oversampling class 1 and undersampling class 3, following the methods above.\n",
    "\n",
    "## Sample Weights\n",
    "\n",
    "Another popular method, depending on machine learning algorithm, is to apply weights to the samples. This is very popular in boosting algorithms and some models that allow access to the learning rate.\n",
    "\n",
    "Essentially, instead of resampling at all, you can assign weights to each sample according to their ratio to the majority class, and it will count more for each and make up for the lack of samples.\n",
    "\n",
    "In essence, it is about the same as oversampling (with some details left out on how it works in practice for especially neural networks), but you train fewer times on fewer samples, which makes it preferable for large problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A note on train/test splitting and stratification\n",
    "\n",
    "It's important to note that balancing is done for the purposes of making sure the model is not skewed during training.\n",
    "\n",
    "You should never balance your validation or holdout (test) set, as that can skew your idea of the performance of the model.\n",
    "\n",
    "In these cases, I would recommend you first split the dataset accordingly, and then balance the training set.\n",
    "\n",
    "However, when you split data for classification, you should use a process called \"Stratification\" according to the output class. The idea is to ensure that the two splits, regardless of their respective sizes, have the same ratio of classes represented amongst themselves.\n",
    "\n",
    "So if we take case 1 above, the ratio between class 1 and class 2 will be 3 in both the training and test set (prior to balancing the train set), after splitting the data set into a train/test set.\n",
    "\n",
    "This is important to make sure that we don't skew our data sets in the process of randomly sampling and splitting them. If we were to split them without stratification, an extreme could be that all the class 1 cases would be in the training set, and all the class 2 cases would be in the test set.\n",
    "\n",
    "Exactly to avoid the last point, you should also (almost) always shuffle your data, as it may have unwanted ordering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try it out\n",
    "\n",
    "We'll load the wine dataset (also available on sklearn) to try out these features. It has three slightly unbalanced classes, representing three different types of wine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wine = load_wine()\n",
    "\n",
    "# Extract the data, target classes and features from the wine dataset\n",
    "data, feature_names = wine.data, wine.feature_names\n",
    "target, target_names = wine.target, wine.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline'] \n",
      "\n",
      "target classes: ['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "print('Features:', feature_names, '\\n\\ntarget classes:', target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representation\n",
    "Let's take a look at the representation of our full target vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([59, 71, 48]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(target, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the ratios using a helper function, so we can see what happens after splitting with stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratios(y_vector):\n",
    "    _, class_counts = np.unique(y_vector, return_counts=True)\n",
    "    ratios = []\n",
    "    for c in class_counts:\n",
    "        ratio = c / class_counts\n",
    "        ratios.append(ratio)\n",
    "    return ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.83098592 1.22916667]\n",
      "[1.20338983 1.         1.47916667]\n",
      "[0.81355932 0.67605634 1.        ]\n"
     ]
    }
   ],
   "source": [
    "r = ratios(target)\n",
    "for ratio in r:\n",
    "    print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the majority class as perspective (in this case the middle row), these ratios also happen to be the sample weights you would use in a sample-weights based approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(target)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because we shuffle and stratify, we need to pass both the data (X) and target (y), and assign them separately\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, shuffle=True, stratify=target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the representation of our train y-vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([41, 50, 33])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, stratified_counts = np.unique(y_train, return_counts=True)\n",
    "stratified_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.82       1.24242424]\n",
      "[1.2195122  1.         1.51515152]\n",
      "[0.80487805 0.66       1.        ]\n"
     ]
    }
   ],
   "source": [
    "r = ratios(y_train)\n",
    "for ratio in r:\n",
    "    print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.85714286 1.2       ]\n",
      "[1.16666667 1.         1.4       ]\n",
      "[0.83333333 0.71428571 1.        ]\n"
     ]
    }
   ],
   "source": [
    "r = ratios(y_test)\n",
    "for ratio in r:\n",
    "    print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll note these ratios are quite close to the original distribution. It's of course hard to do perfect as you cannot always make an even split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing the data\n",
    "\n",
    "Let's start with just getting the indices of all the classes in our y-vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1 = np.where(y_train == 0)[0]\n",
    "class2 = np.where(y_train == 1)[0]\n",
    "class3 = np.where(y_train == 2)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 50 33\n"
     ]
    }
   ],
   "source": [
    "# Which is the majority class?\n",
    "print(len(class1), len(class2), len(class3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority = len(class2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the remaining classes according to the majority size, with replacement\n",
    "class1_up = np.random.choice(class1, size=majority, replace=True)\n",
    "class3_up = np.random.choice(class3, size=majority, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is sampling each of the classes and making a new, balanced, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 13)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.concatenate([class1_up, class2, class3_up])\n",
    "y_train_bal = y_train[indices]\n",
    "X_train_bal = X_train[indices]\n",
    "\n",
    "X_train_bal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice we now have 150 samples total.\n",
    "\n",
    "Let's print the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_bal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's finally print the ratios to convince ourselves we did a good job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.]\n",
      "[1. 1. 1.]\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "r = ratios(y_train_bal)\n",
    "for ratio in r:\n",
    "    print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train_bal)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling\n",
    "\n",
    "Quite similar to above, but with the minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 50 33\n"
     ]
    }
   ],
   "source": [
    "# Which is the minority class?\n",
    "print(len(class1), len(class2), len(class3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "minority = len(class3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the remaining classes according to the majority size, with replacement\n",
    "class1_up = np.random.choice(class1, size=minority, replace=True)\n",
    "class2_up = np.random.choice(class2, size=minority, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is sampling each of the classes and making a new, balanced, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 13)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.concatenate([class1_up, class2_up, class3])\n",
    "y_train_bal = y_train[indices]\n",
    "X_train_bal = X_train[indices]\n",
    "\n",
    "X_train_bal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We now have 99 samples (33\\*3), so we're using less of our dataset than in the above case.**\n",
    "\n",
    "Let's print the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_bal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's finally print the ratios to convince ourselves we did a good job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.]\n",
      "[1. 1. 1.]\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "r = ratios(y_train_bal)\n",
    "for ratio in r:\n",
    "    print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPB0lEQVR4nO3df6xkZX3H8fenLGhFokv3lm6QumBJDSZ1oTfUH8SiaEWMBdOmgbRmaWlWW2gwNU2oJK1tmhSSKk3TxmYV4pooalErtdq6RRpjLWsvdIEFivwQWzYrexUUSBNa8Ns/5lwYLvfuzL0zZ3af+n4lk3vmeZ4z58szh88995w5s6kqJEnt+ZFDXYAkaX0McElqlAEuSY0ywCWpUQa4JDVqwyw3tmnTptqyZcssNylJzbv55pu/U1Vzy9tnGuBbtmxhYWFhlpuUpOYl+dZK7Z5CkaRGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRs30TsxJbLns7w/Zth+44q2HbNuaDfevHw7/395nj8AlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqNGBniS5yf5epJbk9yR5I+69hOT7E5yb5JPJjmq/3IlSUvGOQJ/AnhDVb0S2AqcneRVwJXAVVX1U8AjwEW9VSlJeo6RAV4Dj3dPj+weBbwBuK5r3wmc10eBkqSVjXUOPMkRSfYAB4BdwH3A96rqyW7Ig8DxvVQoSVrRWAFeVU9V1VbgJcDpwMvH3UCS7UkWkiwsLi6ur0pJ0nOs6VMoVfU94Ebg1cCLkyz9m5ovAfatss6Oqpqvqvm5ublJapUkDRnnUyhzSV7cLf8o8CbgLgZB/svdsG3A53qqUZK0gnH+VfrNwM4kRzAI/E9V1eeT3Al8IsmfAP8OXN1jnZKkZUYGeFXdBpy6Qvv9DM6HS5IOAe/ElKRGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRIwM8yQlJbkxyZ5I7klzatb8vyb4ke7rHOf2XK0lasmGMMU8C76mqW5IcA9ycZFfXd1VV/Vl/5UmSVjMywKtqP7C/W34syV3A8X0XJkk6uDWdA0+yBTgV2N01XZLktiTXJNm4yjrbkywkWVhcXJysWknS08YO8CQvBD4NvLuqHgU+CLwM2MrgCP39K61XVTuqar6q5ufm5iavWJIEjBngSY5kEN4fq6rPAFTVQ1X1VFX9APgQcHp/ZUqSlhvnUygBrgbuqqoPDLVvHhr2dmDv9MuTJK1mnE+hvBZ4B3B7kj1d23uBC5JsBQp4AHhnD/VJklYxzqdQvgpkha4vTL8cSdK4vBNTkhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1amSAJzkhyY1J7kxyR5JLu/Zjk+xKck/3c2P/5UqSloxzBP4k8J6qOgV4FXBxklOAy4Abqupk4IbuuSRpRkYGeFXtr6pbuuXHgLuA44FzgZ3dsJ3AeT3VKElawZrOgSfZApwK7AaOq6r9Xde3geNWWWd7koUkC4uLi5PUKkkaMnaAJ3kh8Gng3VX16HBfVRVQK61XVTuqar6q5ufm5iYqVpL0jLECPMmRDML7Y1X1ma75oSSbu/7NwIF+SpQkrWScT6EEuBq4q6o+MNR1PbCtW94GfG765UmSVrNhjDGvBd4B3J5kT9f2XuAK4FNJLgK+BfxKLxVKklY0MsCr6qtAVuk+a7rlSJLG5Z2YktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDVqZIAnuSbJgSR7h9rel2Rfkj3d45x+y5QkLTfOEfhHgLNXaL+qqrZ2jy9MtyxJ0igjA7yqvgI8PINaJElrMMk58EuS3NadYtm42qAk25MsJFlYXFycYHOSpGHrDfAPAi8DtgL7gfevNrCqdlTVfFXNz83NrXNzkqTl1hXgVfVQVT1VVT8APgScPt2yJEmjrCvAk2weevp2YO9qYyVJ/dgwakCSa4EzgU1JHgT+EDgzyVaggAeAd/ZXoiRpJSMDvKouWKH56h5qkSStgXdiSlKjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDXKAJekRo0M8CTXJDmQZO9Q27FJdiW5p/u5sd8yJUnLjXME/hHg7GVtlwE3VNXJwA3dc0nSDI0M8Kr6CvDwsuZzgZ3d8k7gvOmWJUkaZb3nwI+rqv3d8reB41YbmGR7koUkC4uLi+vcnCRpuYkvYlZVAXWQ/h1VNV9V83Nzc5NuTpLUWW+AP5RkM0D388D0SpIkjWO9AX49sK1b3gZ8bjrlSJLGNc7HCK8F/hX46SQPJrkIuAJ4U5J7gDd2zyVJM7Rh1ICqumCVrrOmXIskaQ28E1OSGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY0ywCWpUQa4JDVqwyQrJ3kAeAx4CniyquanUZQkabSJArzz+qr6zhReR5K0Bp5CkaRGTRrgBXwpyc1Jtq80IMn2JAtJFhYXFyfcnCRpyaQBfkZVnQa8Bbg4yeuWD6iqHVU1X1Xzc3NzE25OkrRkogCvqn3dzwPAZ4HTp1GUJGm0dQd4kqOTHLO0DPwCsHdahUmSDm6ST6EcB3w2ydLrfLyq/mEqVUmSRlp3gFfV/cArp1iLJGkN/BihJDXKAJekRhngktQoA1ySGmWAS1KjDHBJapQBLkmNMsAlqVEGuCQ1ygCXpEYZ4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalRBrgkNcoAl6RGGeCS1CgDXJIaZYBLUqMMcElqlAEuSY2aKMCTnJ3k7iT3JrlsWkVJkkZbd4AnOQL4K+AtwCnABUlOmVZhkqSDm+QI/HTg3qq6v6r+B/gEcO50ypIkjbJhgnWPB/5r6PmDwM8tH5RkO7C9e/p4krvXub1NwHfWue5EcuVBuw9ZXSNY19q4f62Nda1Rrpyotpeu1DhJgI+lqnYAOyZ9nSQLVTU/hZKmyrrWxrrWxrrW5nCtC/qpbZJTKPuAE4aev6RrkyTNwCQB/m/AyUlOTHIUcD5w/XTKkiSNsu5TKFX1ZJJLgH8EjgCuqao7plbZc018GqYn1rU21rU21rU2h2td0ENtqappv6YkaQa8E1OSGmWAS1KjDosAH3VLfpLnJflk1787yZahvt/v2u9O8uYZ1/W7Se5McluSG5K8dKjvqSR7usdUL+6OUdeFSRaHtv+bQ33bktzTPbbNuK6rhmr6RpLvDfX1Ml9JrklyIMneVfqT5C+6mm9LctpQX59zNaquX+3quT3J15K8cqjvga59T5KFGdd1ZpLvD71XfzDU19tXa4xR1+8N1bS325+O7fr6nK8TktzY5cAdSS5dYUx/+1hVHdIHgwug9wEnAUcBtwKnLBvz28Bfd8vnA5/slk/pxj8POLF7nSNmWNfrgRd0y7+1VFf3/PFDOF8XAn+5wrrHAvd3Pzd2yxtnVdey8b/D4MJ33/P1OuA0YO8q/ecAXwQCvArY3fdcjVnXa5a2x+DrKnYP9T0AbDpE83Um8PlJ3/9p17Vs7NuAL89ovjYDp3XLxwDfWOH/x972scPhCHycW/LPBXZ2y9cBZyVJ1/6Jqnqiqr4J3Nu93kzqqqobq+q/u6c3MfgsfN8m+QqDNwO7qurhqnoE2AWcfYjqugC4dkrbXlVVfQV4+CBDzgU+WgM3AS9Ospl+52pkXVX1tW67MLt9a5z5Wk2vX62xxrpmsm8BVNX+qrqlW34MuIvBXerDetvHDocAX+mW/OUT8PSYqnoS+D7wY2Ou22ddwy5i8Ft2yfOTLCS5Kcl5U6ppLXX9Uvfn2nVJlm64OizmqzvVdCLw5aHmvuZrlNXq7nOu1mr5vlXAl5LcnMFXVczaq5PcmuSLSV7RtR0W85XkBQxC8NNDzTOZrwxO7Z4K7F7W1ds+1vut9D8MkvwaMA/8/FDzS6tqX5KTgC8nub2q7ptRSX8HXFtVTyR5J4O/Xt4wo22P43zguqp6aqjtUM7XYSvJ6xkE+BlDzWd0c/XjwK4k/9Edoc7CLQzeq8eTnAP8LXDyjLY9jrcB/1JVw0frvc9Xkhcy+KXx7qp6dJqvfTCHwxH4OLfkPz0myQbgRcB3x1y3z7pI8kbgcuAXq+qJpfaq2tf9vB/4Zwa/mWdSV1V9d6iWDwM/O+66fdY15HyW/Ynb43yNslrdh/yrIpL8DIP379yq+u5S+9BcHQA+y/ROG45UVY9W1ePd8heAI5Ns4jCYr87B9q1e5ivJkQzC+2NV9ZkVhvS3j/VxYn+NFwE2MDh5fyLPXPx4xbIxF/Psi5if6pZfwbMvYt7P9C5ijlPXqQwu3Jy8rH0j8LxueRNwD1O6oDNmXZuHlt8O3FTPXDT5Zlffxm752FnV1Y17OYOLSpnFfHWvuYXVL8q9lWdfYPp633M1Zl0/yeCazmuWtR8NHDO0/DXg7BnW9RNL7x2DIPzPbu7Gev/7qqvrfxGD8+RHz2q+uv/2jwJ/fpAxve1jU5vcCSfhHAZXb+8DLu/a/pjBUS3A84G/6XborwMnDa17ebfe3cBbZlzXPwEPAXu6x/Vd+2uA27ud+HbgohnX9afAHd32bwRePrTub3TzeC/w67Osq3v+PuCKZev1Nl8Mjsb2A//L4BzjRcC7gHd1/WHwD5Pc1217fkZzNaquDwOPDO1bC137Sd083dq9x5fPuK5Lhvatmxj6BbPS+z+ruroxFzL4UMPwen3P1xkMzrHfNvRenTOrfcxb6SWpUYfDOXBJ0joY4JLUKANckhplgEtSowxwSWqUAS5JjTLAJalR/wekKi0GsW2aLgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train_bal)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed Sampling\n",
    "\n",
    "There's a few approaches.\n",
    "We can either just take the middle class, as describes in the top, or we can sample according to the average representation - using the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean sample (integer) 41\n",
      "Sample class lengths: 41 50 33\n"
     ]
    }
   ],
   "source": [
    "# What is the mean?\n",
    "print(\"Mean sample (integer)\", int(np.mean([len(class1), len(class2), len(class3)])))\n",
    "print(\"Sample class lengths:\", len(class1), len(class2), len(class3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, they're one and the same. Using the mean is simpler to calculate, but bears some risk in the groups where you're close to the amount of samples but you want to sample without replacement.\n",
    "\n",
    "So let's just simplify it by entirely sampling the middle class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle = int(np.mean([len(class1), len(class2), len(class3)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the remaining classes according to the majority size, with replacement\n",
    "class2_down = np.random.choice(class2, size=middle, replace=True)\n",
    "class3_up = np.random.choice(class3, size=middle, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is sampling each of the classes and making a new, balanced, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123, 13)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.concatenate([class1, class2_down, class3_up])\n",
    "y_train_bal = y_train[indices]\n",
    "X_train_bal = X_train[indices]\n",
    "\n",
    "X_train_bal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 123 samples (41\\*3), so we're hitting a good middle ground here.\n",
    "\n",
    "Let's print the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_bal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's finally print the ratios to convince ourselves we did a good job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1.]\n",
      "[1. 1. 1.]\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "r = ratios(y_train_bal)\n",
    "for ratio in r:\n",
    "    print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train_bal)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample weights\n",
    "\n",
    "As mentioned above, calculating the sample weights for each class is most easily done according to the ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.82       1.24242424]\n",
      "[1.2195122  1.         1.51515152]\n",
      "[0.80487805 0.66       1.        ]\n"
     ]
    }
   ],
   "source": [
    "r = ratios(y_train)\n",
    "for ratio in r:\n",
    "    print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It shouldn't really matter which one you pick, but I prefer making my choice around 1, which means taking the ratios according to the majority. That's the second row in this instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.2195122 , 1.        , 1.51515152])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_ratios = r[1]\n",
    "class_ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to make an array with all the sample weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.2195122 , 1.2195122 , 1.51515152, 1.2195122 , 1.51515152,\n",
       "       1.2195122 , 1.51515152, 1.2195122 , 1.2195122 , 1.        ,\n",
       "       1.        , 1.        , 1.2195122 , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.2195122 ,\n",
       "       1.2195122 , 1.51515152, 1.        , 1.2195122 , 1.        ,\n",
       "       1.2195122 , 1.        , 1.2195122 , 1.2195122 , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.51515152, 1.51515152, 1.2195122 , 1.2195122 , 1.2195122 ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.2195122 ,\n",
       "       1.        , 1.2195122 , 1.51515152, 1.        , 1.2195122 ,\n",
       "       1.51515152, 1.51515152, 1.2195122 , 1.        , 1.2195122 ,\n",
       "       1.        , 1.        , 1.        , 1.2195122 , 1.2195122 ,\n",
       "       1.        , 1.51515152, 1.51515152, 1.51515152, 1.2195122 ,\n",
       "       1.2195122 , 1.51515152, 1.51515152, 1.51515152, 1.51515152,\n",
       "       1.2195122 , 1.51515152, 1.        , 1.2195122 , 1.51515152,\n",
       "       1.51515152, 1.        , 1.        , 1.        , 1.2195122 ,\n",
       "       1.        , 1.2195122 , 1.51515152, 1.        , 1.51515152,\n",
       "       1.        , 1.51515152, 1.51515152, 1.        , 1.51515152,\n",
       "       1.51515152, 1.2195122 , 1.51515152, 1.2195122 , 1.51515152,\n",
       "       1.51515152, 1.        , 1.51515152, 1.51515152, 1.2195122 ,\n",
       "       1.2195122 , 1.        , 1.        , 1.        , 1.2195122 ,\n",
       "       1.        , 1.51515152, 1.        , 1.        , 1.2195122 ,\n",
       "       1.2195122 , 1.2195122 , 1.2195122 , 1.2195122 , 1.        ,\n",
       "       1.51515152, 1.        , 1.2195122 , 1.        , 1.        ,\n",
       "       1.        , 1.2195122 , 1.        , 1.51515152])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weights = np.array([class_ratios[y] for y in y_train])\n",
    "sample_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we can use these weights directly when we train a model by multiplying it to, i.e. the learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to sample from the dataset using these weights, however then we first have to normalize them so they sum to 1.\n",
    "\n",
    "You'll notice as we run this sampling for different sizes, it'll consistently be fairly close to 1, but due to the probabilistic nature it's hard to guarantee. It'll generally be more stable in its fairness on balancing the more you sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(weights):\n",
    "    return weights / weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(data, size, weights):\n",
    "    return np.random.choice(y_train, size=2000, replace=True, p=normalize(sample_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.98088235 1.02143951]\n",
      "[1.01949025 1.         1.04134763]\n",
      "[0.97901049 0.96029412 1.        ]\n"
     ]
    }
   ],
   "source": [
    "y_train_bal = sample(y_train, size=10, weights=normalize(sample_weights))\n",
    "r = ratios(y_train_bal)\n",
    "for ratio in r:\n",
    "    print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.9360119  0.89985694]\n",
      "[1.06836248 1.         0.96137339]\n",
      "[1.11128776 1.04017857 1.        ]\n"
     ]
    }
   ],
   "source": [
    "y_train_bal = sample(y_train, size=100, weights=normalize(sample_weights))\n",
    "r = ratios(y_train_bal)\n",
    "for ratio in r:\n",
    "    print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.95461201 0.98045113]\n",
      "[1.04754601 1.         1.02706767]\n",
      "[1.01993865 0.97364568 1.        ]\n"
     ]
    }
   ],
   "source": [
    "y_train_bal = sample(y_train, size=200, weights=normalize(sample_weights))\n",
    "r = ratios(y_train_bal)\n",
    "for ratio in r:\n",
    "    print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.04739336 0.94176136]\n",
      "[0.95475113 1.         0.89914773]\n",
      "[1.06184012 1.1121643  1.        ]\n"
     ]
    }
   ],
   "source": [
    "y_train_bal = sample(y_train, size=1000, weights=normalize(sample_weights))\n",
    "r = ratios(y_train_bal)\n",
    "for ratio in r:\n",
    "    print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.05965463 0.98110465]\n",
      "[0.9437037  1.         0.92587209]\n",
      "[1.01925926 1.08006279 1.        ]\n"
     ]
    }
   ],
   "source": [
    "y_train_bal = sample(y_train, size=10000, weights=normalize(sample_weights))\n",
    "r = ratios(y_train_bal)\n",
    "for ratio in r:\n",
    "    print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAASqElEQVR4nO3df6zd9X3f8edrOJCVZtjArWfZXkxUqxGRFnCvMpJGXRLWFZw1ZmqLiLrhME9uN1olyrSNLtJ+adLIP6NFm5iskM1UKQmlzfBS2tUzRNUWmfSSEAMhlIsbZluAbwk4pajpyN7743ycHN/c63vuvedcO58+H9LR+Xw/n8/3fN/3e7+87tffc86XVBWSpL78pXNdgCRp/Ax3SeqQ4S5JHTLcJalDhrskdWjduS4A4PLLL69t27ad6zIk6fvKo48++sdVNbXQ2HkR7tu2bWNmZuZclyFJ31eSPLfYmJdlJKlDhrskdWjJcE/yI0keG3p8M8lHklya5GCSZ9rzhjY/Se5MMpvkSJIdk/8xJEnDlgz3qnq6qq6qqquAHwVeAz4L3AYcqqrtwKG2DHA9sL099gJ3TaBuSdJZLPeyzLXAs1X1HLAL2N/69wM3tPYu4J4aOAysT7JpHMVKkkaz3HC/Cbi3tTdW1fOt/QKwsbU3A8eG1jne+s6QZG+SmSQzc3NzyyxDknQ2I4d7kguBDwC/MX+sBreWXNbtJatqX1VNV9X01NSCH9OUJK3Qcs7crwe+VFUvtuUXT19uac8nW/8JYOvQeltanyRpjSwn3D/Idy/JABwAdrf2buCBof6b26dmrgFODV2+kSStgZG+oZrkYuAngJ8f6r4duC/JHuA54MbW/yCwE5hl8MmaW8ZWrSRNwLbbfvucbfvrt79/Iq87UrhX1Z8Cl83re4nBp2fmzy3g1rFUJ0laEb+hKkkdMtwlqUPnxV0hV6PHa2WStFqeuUtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nq0Pf97QekSfL2Fvp+5Zm7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdGinck6xPcn+SryV5Ksk7k1ya5GCSZ9rzhjY3Se5MMpvkSJIdk/0RJEnzjXrm/qvA71bVW4G3A08BtwGHqmo7cKgtA1wPbG+PvcBdY61YkrSkJcM9ySXAjwN3A1TVn1fVK8AuYH+bth+4obV3AffUwGFgfZJNY65bknQWo5y5XwHMAf8lyZeTfCLJxcDGqnq+zXkB2Njam4FjQ+sfb31nSLI3yUySmbm5uZX/BJKk7zFKuK8DdgB3VdXVwJ/y3UswAFRVAbWcDVfVvqqarqrpqamp5awqSVrCKOF+HDheVY+05fsZhP2Lpy+3tOeTbfwEsHVo/S2tT5K0RpYM96p6ATiW5Eda17XAV4EDwO7Wtxt4oLUPADe3T81cA5waunwjSVoDo97y95eATyW5EDgK3MLgD8N9SfYAzwE3trkPAjuBWeC1NleStIZGCveqegyYXmDo2gXmFnDr6sqSJK2G31CVpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6tBI4Z7k60keT/JYkpnWd2mSg0meac8bWn+S3JlkNsmRJDsm+QNIkr7Xcs7c31tVV1XVdFu+DThUVduBQ20Z4Hpge3vsBe4aV7GSpNGs5rLMLmB/a+8Hbhjqv6cGDgPrk2xaxXYkScs0argX8HtJHk2yt/VtrKrnW/sFYGNrbwaODa17vPWdIcneJDNJZubm5lZQuiRpMetGnPfuqjqR5IeAg0m+NjxYVZWklrPhqtoH7AOYnp5e1rqSpLMb6cy9qk6055PAZ4F3AC+evtzSnk+26SeArUOrb2l9kqQ1smS4J7k4yZtOt4G/DTwBHAB2t2m7gQda+wBwc/vUzDXAqaHLN5KkNTDKZZmNwGeTnJ7/61X1u0n+ALgvyR7gOeDGNv9BYCcwC7wG3DL2qiVJZ7VkuFfVUeDtC/S/BFy7QH8Bt46lOknSivgNVUnqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOjRzuSS5I8uUkn2vLVyR5JMlsks8kubD1X9SWZ9v4tgnVLklaxHLO3D8MPDW0/HHgjqr6YeBlYE/r3wO83PrvaPMkSWtopHBPsgV4P/CJthzgfcD9bcp+4IbW3tWWaePXtvmSpDUy6pn7rwD/DPh/bfky4JWqer0tHwc2t/Zm4BhAGz/V5p8hyd4kM0lm5ubmVla9JGlBS4Z7kr8DnKyqR8e54araV1XTVTU9NTU1zpeWpL/w1o0w58eADyTZCbwR+CvArwLrk6xrZ+dbgBNt/glgK3A8yTrgEuClsVcuSVrUkmfuVfXLVbWlqrYBNwEPVdXPAQ8DP9Om7QYeaO0DbZk2/lBV1VirliSd1Wo+5/7PgY8mmWVwTf3u1n83cFnr/yhw2+pKlCQt1yiXZb6jqj4PfL61jwLvWGDOnwE/O4baJEkr5DdUJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjq0ZLgneWOSLyb5SpInk/yb1n9FkkeSzCb5TJILW/9FbXm2jW+b8M8gSZpnlDP3bwHvq6q3A1cB1yW5Bvg4cEdV/TDwMrCnzd8DvNz672jzJElraMlwr4FX2+Ib2qOA9wH3t/79wA2tvast08avTZJxFSxJWtpI19yTXJDkMeAkcBB4Fnilql5vU44Dm1t7M3AMoI2fAi4bY82SpCWMFO5V9e2qugrYArwDeOtqN5xkb5KZJDNzc3OrfTlJ0pBlfVqmql4BHgbeCaxPsq4NbQFOtPYJYCtAG78EeGmB19pXVdNVNT01NbWy6iVJCxrl0zJTSda39l8GfgJ4ikHI/0ybtht4oLUPtGXa+ENVVWOsWZK0hHVLT2ETsD/JBQz+GNxXVZ9L8lXg00n+HfBl4O42/27g15LMAt8AbppA3ZKks1gy3KvqCHD1Av1HGVx/n9//Z8DPjqU6SdKK+A1VSeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4tGe5JtiZ5OMlXkzyZ5MOt/9IkB5M80543tP4kuTPJbJIjSXZM+oeQJJ1plDP314F/UlVXAtcAtya5ErgNOFRV24FDbRngemB7e+wF7hp71ZKks1oy3Kvq+ar6Umv/CfAUsBnYBexv0/YDN7T2LuCeGjgMrE+yadyFS5IWt6xr7km2AVcDjwAbq+r5NvQCsLG1NwPHhlY73vokSWtk5HBP8oPAbwIfqapvDo9VVQG1nA0n2ZtkJsnM3NzcclaVJC1hpHBP8gYGwf6pqvqt1v3i6cst7flk6z8BbB1afUvrO0NV7auq6aqanpqaWmn9kqQFjPJpmQB3A09V1X8YGjoA7G7t3cADQ/03t0/NXAOcGrp8I0laA+tGmPNjwN8HHk/yWOv7F8DtwH1J9gDPATe2sQeBncAs8BpwyzgLliQtbclwr6r/BWSR4WsXmF/ArausS5K0Cn5DVZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdWjJcE/yySQnkzwx1HdpkoNJnmnPG1p/ktyZZDbJkSQ7Jlm8JGlho5y5/1fgunl9twGHqmo7cKgtA1wPbG+PvcBd4ylTkrQcS4Z7Vf0+8I153buA/a29H7hhqP+eGjgMrE+yaUy1SpJGtNJr7hur6vnWfgHY2NqbgWND8463vu+RZG+SmSQzc3NzKyxDkrSQVb+hWlUF1ArW21dV01U1PTU1tdoyJElDVhruL56+3NKeT7b+E8DWoXlbWp8kaQ2tNNwPALtbezfwwFD/ze1TM9cAp4Yu30iS1si6pSYkuRd4D3B5kuPAvwJuB+5Lsgd4DrixTX8Q2AnMAq8Bt0ygZknSEpYM96r64CJD1y4wt4BbV1uUJGl1/IaqJHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocmEu5JrkvydJLZJLdNYhuSpMWNPdyTXAD8J+B64Ergg0muHPd2JEmLm8SZ+zuA2ao6WlV/Dnwa2DWB7UiSFrFuAq+5GTg2tHwc+BvzJyXZC+xti68meXqF27sc+OMVrrsq+fhZh89ZXUuwruU5X48vcJ8t13lZVz6+qrrevNjAJMJ9JFW1D9i32tdJMlNV02Moaaysa3msa/nO19qsa3kmVdckLsucALYOLW9pfZKkNTKJcP8DYHuSK5JcCNwEHJjAdiRJixj7ZZmqej3JLwL/A7gA+GRVPTnu7QxZ9aWdCbGu5bGu5Ttfa7Ou5ZlIXamqSbyuJOkc8huqktQhw12SOnReh/tStzFIclGSz7TxR5JsGxr75db/dJKfXOO6Pprkq0mOJDmU5M1DY99O8lh7jPWN5hHq+lCSuaHt/8Ohsd1JnmmP3Wtc1x1DNf1hkleGxia5vz6Z5GSSJxYZT5I7W91HkuwYGpvI/hqhpp9rtTye5AtJ3j409vXW/1iSmXHVtIza3pPk1NDv618OjU3sliQj1PVPh2p6oh1Tl7axieyzJFuTPNxy4MkkH15gzmSPr6o6Lx8M3ox9FngLcCHwFeDKeXP+MfCfW/sm4DOtfWWbfxFwRXudC9awrvcCP9Da/+h0XW351XO4vz4E/McF1r0UONqeN7T2hrWqa978X2LwJvxE91d77R8HdgBPLDK+E/gdIMA1wCNrsL+Wquldp7fF4BYfjwyNfR24/Bzur/cAn1vtMTDuuubN/SngoUnvM2ATsKO13wT84QL/PU70+Dqfz9xHuY3BLmB/a98PXJskrf/TVfWtqvojYLa93prUVVUPV9VrbfEwg8/6T9pqbvvwk8DBqvpGVb0MHASuO0d1fRC4d0zbPquq+n3gG2eZsgu4pwYOA+uTbGKC+2upmqrqC22bsHbH1ultL7W/FjPRW5Iss641Ob6q6vmq+lJr/wnwFINv7w+b6PF1Pof7QrcxmL9zvjOnql4HTgGXjbjuJOsatofBX+fT3phkJsnhJDeMqabl1PXT7Z+A9yc5/WWz82J/tctXVwAPDXVPan+NYrHaJ7m/lmP+sVXA7yV5NIPbe5wL70zylSS/k+Rtre+82F9JfoBBSP7mUPfE91kGl4uvBh6ZNzTR4+uc3X7gL4Ikfw+YBv7mUPebq+pEkrcADyV5vKqeXaOS/jtwb1V9K8nPM/hXz/vWaNujuAm4v6q+PdR3LvfXeSvJexmE+7uHut/d9tUPAQeTfK2d1a6VLzH4fb2aZCfw34Dta7j9pfwU8L+ravgsf6L7LMkPMvhj8pGq+ua4XncU5/OZ+yi3MfjOnCTrgEuAl0Zcd5J1keRvAR8DPlBV3zrdX1Un2vNR4PMM/qKvSV1V9dJQLZ8AfnTUdSdZ15CbmPdP5gnur1EsVvs5vcVGkr/O4Pe3q6peOt0/tK9OAp9lfJciR1JV36yqV1v7QeANSS7n/LklydmOr7HvsyRvYBDsn6qq31pgymSPr3G/kTCuB4N/VRxl8M/002/CvG3enFs58w3V+1r7bZz5hupRxveG6ih1Xc3gDaTt8/o3ABe19uXAM4zpjaUR69o01P67wOH67hs4f9Tq29Dal65VXW3eWxm8uZW12F9D29jG4m8Qvp8z3/D64qT31wg1/TUG7yG9a17/xcCbhtpfAK4b574aoba/evr3xyAk/0/bdyMdA5Oqq41fwuC6/MVrsc/az30P8CtnmTPR42usv/gJHEg7GbzL/Czwsdb3bxmcDQO8EfiNdrB/EXjL0Lofa+s9DVy/xnX9T+BF4LH2OND63wU83g7ux4E9a1zXvweebNt/GHjr0Lr/oO3HWeCWtayrLf9r4PZ56016f90LPA/8XwbXNfcAvwD8QhsPg//xzLNt+9OT3l8j1PQJ4OWhY2um9b+l7aevtN/xx8a5r0as7ReHjq/DDP0BWugYWKu62pwPMfiQxfB6E9tnDC6XFXBk6He1cy2PL28/IEkdOp+vuUuSVshwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR36/2yCumBfS/xiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train_bal)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
