{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Problem\n",
    "\n",
    "**Author: [Kevin Brol√∏s](https://abzu.ai/team)**\n",
    "\n",
    "The first part of any machine learning journey is defining the problem.\n",
    "\n",
    "Often times, this requires further data analysis to crystallize, so this notebook will focus on introducing the different data sets we'll be working on going forward.\n",
    "\n",
    "Defining the problem in a machine-learning context requires part domain knowledge, part business knowledge and part algorithm knowledge.\n",
    "\n",
    "That is:\n",
    "\n",
    "## Domain knowledge: \n",
    "* What are we dealing with?\n",
    "    * What do the input features mean or represent?\n",
    "    * Are they important to our problem, and why or why not?\n",
    "    * Are they representative of the truth or real world (More on this when we get to analysis)\n",
    "    \n",
    "## Business knowledge: \n",
    "* What is the business value?\n",
    "    * What kind of problem can we phrase that drives a business value, or change?\n",
    "    * Are we interested in classifying future samples using a model?\n",
    "        * Examples of this could be:\n",
    "            * Determining what the kind of flower is\n",
    "            * Know the difference between bird species from their features\n",
    "            * Determining if a machine needs maintenance\n",
    "            * If a patient will contract a disease\n",
    "            * Alerting if a credit card transaction is fraudulent\n",
    "            * Indicating if a lender will default\n",
    "    * Are we interested in predicting a value or metric?\n",
    "        * Examples of this include:\n",
    "            * Predicting the leaf size of a flower\n",
    "            * The airspeed velocity of an unladen african swallow\n",
    "            * The cost of maintenance for a machine over time\n",
    "            * The amount of people who will be hospitalized in a given period\n",
    "            * The amount of credit card transactions a bank needs to support on a given day\n",
    "            * The return on investment for loaning out money\n",
    "\n",
    "## Algorithm knowledge: \n",
    "* Which algorithms would be suited for which problem?\n",
    "    * Classification problems are best solved with some algorithms, such as (of the ones we're looking into):\n",
    "        * Logistic regressions\n",
    "        * Decision Trees/Random Forests\n",
    "        * Neural Networks (for large datasets - often with many input features)\n",
    "    * Regression problems are best solved with:\n",
    "        * Linear regressions\n",
    "        * Regression Trees/Forests\n",
    "        * Neural Networks (for large datasets - often with many input features)\n",
    "    * Knowing how to process and prepare the data for the given problem\n",
    "        * Balancing\n",
    "        * Encoding (Sparse categorical or One-Hot)\n",
    "        * Filtering\n",
    "        * Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many ways to frame a problem\n",
    "\n",
    "Most problems can be defined as either a regression or classification problem.\n",
    "Sometimes, simplifying the problem to a binary or binned classification problem can simplify it immensely, while still providing good value to the business case. It requires a good understanding of both the domain and business angle to know when and how to make this tradeoff.\n",
    "\n",
    "Performance on regression cases (due to their \"exact\" nature), can sometimes be hard to chase, and it's useful to know to reframe a problem from one to the other depending on the results, if you still want to extract signal - and ultimately value - from the data you have available.\n",
    "\n",
    "Data sets in the wild are typically less forgiving than what you'll find here, so keep that in mind as you learn the tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# The Datasets:\n",
    "\n",
    "\n",
    "## The Iris Dataset\n",
    "\n",
    "A common beginner's dataset.\n",
    "The [iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set) consists of 150 samples equally distributed over three classes of the iris flower, namely 'Iris Setosa', 'Iris Versicolor' and 'Iris Virginica'.\n",
    "\n",
    "50 samples have been taken of each flower, so it's a well-balanced dataset, and the samples consist of four continunous features measured on real-world samples, as listed below:\n",
    "1. Sepal Length (cm)\n",
    "2. Sepal Width (cm)\n",
    "3. Petal Length (cm)\n",
    "4. Petal Width (cm)\n",
    "\n",
    "For the non-botanically inclined - The petals are each individual leaf on the flower when in bloom. The sepals of the flower are the green leafy things by the foot of the flower near the stem protecting the flower petals.\n",
    "\n",
    "### Defining the problem\n",
    "The classical example is to attempt to classify the flower from the four features.\n",
    "\n",
    "It is such a popular dataset because you can solve it with pretty much any machine learning algorithm.\n",
    "\n",
    "You can even attempt to predict either of the four \"input\" parameters using the class and the remaining parameters, as a regression exercise.\n",
    "\n",
    "### Getting the dataset\n",
    "\n",
    "It's really easy to get the dataset, as it comes with any installation of scikit-learn due to its popularity. Follow along with the python code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Iris dataset from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the data, target classes and features from the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, feature_names = iris.data, iris.feature_names\n",
    "target, target_names = iris.target, iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns in the dataset:\n",
      " ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Unique classes in the target column:\n",
      " ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature columns in the dataset:\\n\", feature_names)\n",
    "print(\"Unique classes in the target column:\\n\", target_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
